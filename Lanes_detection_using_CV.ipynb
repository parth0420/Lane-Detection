{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Lanes detection using CV.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3MJ8o8ZeZi2"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsq0ZItweZjD"
      },
      "source": [
        "def canny(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) #Applies the Grayscale transform (image to black and white)\n",
        "    blur = cv2.GaussianBlur(gray,( 5 , 5 ), 0)     #Applies a Gaussian Noise kernel (Removes Noice)\n",
        "    canny = cv2.Canny(blur , 50 ,150)   # Applies the Canny transform     \n",
        "    return canny"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aWy9XvoeZjG"
      },
      "source": [
        "def region_of_interest(img):\n",
        "    \"\"\"\n",
        "    Applies an image mask.    \n",
        "    Only keeps the region of the image defined by the polygon\n",
        "    formed from `vertices`. The rest of the image is set to black.\n",
        "    \"\"\"\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    #vertices for our traingle of interest\n",
        "    polygons = np.array([\n",
        "        [ (0, height), (width / 2, height / 3), (width, height) ]\n",
        "    ], dtype=np.int32)                                                \n",
        "    \n",
        "    mask = np.zeros_like(img)   #black mask image with same shape as the image\n",
        "    cv2.fillPoly(mask, polygons , 255 )   #fill the mask image with the traingle\n",
        "    masked_img = cv2.bitwise_and(img, mask)  #Cropping the area of interest wusing AND operator between the image and the mask\n",
        "    return masked_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW2yfGFzeZjH"
      },
      "source": [
        "def display_lines(img , lines):\n",
        "    line_img = np.zeros_like(img)\n",
        "    if lines is not None:\n",
        "        for x1,y1, x2, y2 in lines:\n",
        "            cv2.line(line_img , (x1,y1), (x2,y2) , (255, 0, 0), 10 )\n",
        "    return line_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfp3HG5reZjI"
      },
      "source": [
        "def avg_slope_intercept(img , lines ):\n",
        "    left_fit = []\n",
        "    right_fit = []\n",
        "    for line in lines:\n",
        "        x1,y1, x2, y2 = line.reshape(4)\n",
        "        parameters = np.polyfit((x1,x2), (y1,y2) ,1 )\n",
        "        slope = parameters[0]\n",
        "        intercept = parameters[1]\n",
        "        if slope < 0:\n",
        "            left_fit.append((slope,intercept))\n",
        "        else:\n",
        "            right_fit.append((slope,intercept))\n",
        "    \n",
        "    if left_fit:\n",
        "        left_fit_avg = np.average(left_fit, axis=0)\n",
        "        left_line = make_coordinates(img , left_fit_avg)\n",
        "    else:\n",
        "        left_line = [0,0,0,0]\n",
        "        \n",
        "    if right_fit:\n",
        "        right_fit_avg = np.average(right_fit, axis=0)\n",
        "        right_line = make_coordinates(img , right_fit_avg)\n",
        "    else:\n",
        "        right_line = [0,0,0,0]\n",
        "        \n",
        "    #print(\"Right:\",right_line)\n",
        "    #print(\"Left:\",left_line)\n",
        "\n",
        "    #left_line = make_coordinates(img , left_fit_avg)\n",
        "    #right_line = make_coordinates(img , right_fit_avg)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return np.array([left_line, right_line])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsEo5CyEeZjJ"
      },
      "source": [
        "def make_coordinates(image , line_param):\n",
        "    try:\n",
        "        slope, intercept = line_param\n",
        "    except TypeError:\n",
        "        slope, intercept = 0,0\n",
        "        \n",
        "    y1 = image.shape[0]\n",
        "    y2 = int(y1 * (3/5))\n",
        "    x1 = int((y1 - intercept)/slope)\n",
        "    x2 = int((y2 - intercept)/slope)\n",
        "\n",
        "    return np.array([x1, y1, x2, y2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25d8f4GaeZjJ"
      },
      "source": [
        "def get_lines_image(image):\n",
        "    \n",
        "    #image = cv2.imread(file)  # if image path is passed use this\n",
        "    #image = file               # if frames are passed \n",
        "    #print(image.shape)\n",
        "    \n",
        "    height = image.shape[0]\n",
        "    width = image.shape[1]\n",
        "    \n",
        "    canny_image = canny(image)\n",
        "    \n",
        "    cropped_image =  region_of_interest(canny_image)\n",
        "    \n",
        "    lines = cv2.HoughLinesP( cropped_image , 2 , np.pi/180 , 100 , np.array([]) , minLineLength = 40 , maxLineGap = 5)\n",
        "    \n",
        "    avg_lines = avg_slope_intercept(image , lines)\n",
        "    \n",
        "    line_image = display_lines(image, avg_lines)\n",
        "    \n",
        "    merged_image = cv2.addWeighted(image, 0.8 , line_image ,1 ,1)\n",
        "    \n",
        "    return merged_image    #return line_image for model labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuLawCKleZjK"
      },
      "source": [
        "#For video\n",
        "def video_lines(file):\n",
        "    cap = cv2.VideoCapture(file)\n",
        "    while(cap.isOpened()):\n",
        "        _, frame = cap.read()\n",
        "        images = get_lines_image(frame)\n",
        "        cv2.imshow( 'result' , images ) # Change to line_image for Labels\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16qHLLYjeZjL",
        "outputId": "778412f5-2527-4d7e-98ec-021bdf9fb2ce"
      },
      "source": [
        "file = \"test2.mp4\"\n",
        "video_lines(file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OverflowError",
          "evalue": "Python int too large to convert to C long",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-9-e25b7b32df11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"test2.mp4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvideo_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-8-cb4055903b88>\u001b[0m in \u001b[0;36mvideo_lines\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lines_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'result'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m# Change to line_image for Labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-7-33c0519eb667>\u001b[0m in \u001b[0;36mget_lines_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mavg_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_slope_intercept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mline_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mmerged_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mline_image\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-4-f28ad81105ee>\u001b[0m in \u001b[0;36mdisplay_lines\u001b[1;34m(img, lines)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_img\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mline_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-8PK8j8eZjN"
      },
      "source": [
        "file = \"690 img 2.jpg\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgzHA7W1eZjO"
      },
      "source": [
        "cv2.imshow( 'result' , get_lines_image(file) )\n",
        "cv2.waitKey(0) # Use this for image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVyHbmcQeZjO"
      },
      "source": [
        "file"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}